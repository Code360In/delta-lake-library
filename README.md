# Delta Lake Library

Data Python artifact wheel file is installed in the Spark cluster and can be used in all cluster notebooks.

The package contains data models, libraries to ingest data from Kafka and Spark jobs creation scripts.
- delta_lake_catalog: table structures with SQL DDL creation statements.
- delta_lake_library: libraries to ingest data from Confluent and store it in the delta lake.
- delta_lake_deployment: library wheel file deployment and Spark jobs creation scripts.
